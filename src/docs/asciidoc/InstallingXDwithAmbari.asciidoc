Installing Spring XD using Ambari
=================================

These instructions apply to an installation using link:http://pivotalhd.docs.pivotal.io/docs/install-ambari.html[Pivotal Ambari] as well as link:http://docs.hortonworks.com/HDPDocuments/Ambari-2.0.1.0/index.html[Hortonworks Ambari] using Red Hat Enterprise Linux 6.5 or CentOS 6.5. 

NOTE: These instructions are for *Spring XD version 1.3.0*. Instructions for Spring XD 1.2.x can be found link:https://github.com/spring-projects/spring-xd-ambari/blob/1a229c77af5df6c063546c9d6f6dc1f1e9285052/src/docs/asciidoc/InstallingXDwithAmbari.asciidoc[here].

This document describes the initial installation process. For upgrade instructions please refer to link:UpgradingXDwithAmbari.asciidoc[Upgrading to Spring XD 1.3.0.RELEASE using Ambari].

NOTE: At the moment we support Apache Ambari versions 1.7.0, 1.7.1, 2.0.1 and 2.1.2.

For instructions to set up a single-node VM using Pivotal Ambari and Pivotal HD 3.0 see link:InstallingPHDwithAmbari.asciidoc[Installing Pivotal HD 3.0 on single-node VM using Ambari]

For instructions to set up a single-node VM using Hortonworks Ambari and HDP 2.2 see link:InstallingHDPwithAmbari.asciidoc[Installing Hortonworks HDP 2.2 on single-node VM using Ambari]

=== Preparing HDFS directories

There are certain directories that need to have the correct permissions for everything to work smoothly.

Check the permissions of a directory using:

[source]
----
hdfs dfs -ls -d <directory>
----

==== HDFS `/user` directory

Check the permission for the HDFS `/user` directory. If the directory doesn't exist create it with:

[source]
----
HADOOP_USER_NAME=hdfs hdfs dfs -mkdir /user
----

If you just created the directory or the permissions aren't `drwxrwxrwx` then set the permissions using:

[source]
----
HADOOP_USER_NAME=hdfs hdfs dfs -chmod 777 /user
----

==== HDFS `/tmp/yarn` directory

Check the permission for the HDFS `/tmp/yarn` directory. If the directory doesn't exist create it with:

[source]
----
HADOOP_USER_NAME=yarn hdfs dfs -mkdir /tmp/yarn
----

If you just created the directory or the permissions aren't `drwxrwxrwx` then set the permissions using:

[source]
----
HADOOP_USER_NAME=yarn hdfs dfs -chmod 777 /tmp/yarn
----

==== HDFS `/tmp/hadoop-yarn/staging/history` directory

Check the permission for the HDFS `/tmp/hadoop-yarn/staging/history` directory. If the directory doesn't exist create it and set the permissions with:

[source]
----
HADOOP_USER_NAME=yarn hdfs dfs -mkdir -p /tmp/hadoop-yarn/staging/history
HADOOP_USER_NAME=yarn hdfs dfs -chmod -R 777 /tmp/hadoop-yarn
----

If the permissions aren't `drwxrwxrwx` then set the permissions, with HADOOP_USER_NAME set as the owner of the directory, using:

[source]
----
HADOOP_USER_NAME=<owner-of-directory> hdfs dfs -chmod 777 /tmp/hadoop-yarn
HADOOP_USER_NAME=<owner-of-directory> hdfs dfs -chmod 777 /tmp/hadoop-yarn/staging
HADOOP_USER_NAME=<owner-of-directory> hdfs dfs -chmod 777 /tmp/hadoop-yarn/staging/history
----

=== Configuring the Spring XD YUM repository

We need to copy the Spring XD repository definition into the local YUM repository on the machine used for the Ambari server.

[source]
----
# wget -nv http://repo.spring.io/yum-release/spring-xd/1.3/spring-xd-1.3.repo -O /etc/yum.repos.d/spring-xd-1.3.repo
----

Check that the Spring XD YUM repo is available using:

[source]
----
# yum repolist
----

Now we can install the Spring XD Ambari plug-in file to the Ambari server machine using YUM.

For Pivotal HD use:

[source]
----
# yum install spring-xd-plugin-phd
----

For Hortonworks HDP use:

[source]
----
# yum install spring-xd-plugin-hdp
----

We now need to restart the Ambari server to pick up this new plugin:

[source]
----
# ambari-server restart
----

=== Install Redis 

You can build Redis from source or you can use RPMs that are available from the link:https://fedoraproject.org/wiki/EPEL[EPEL] project. Source is available from the link:http://redis.io/download[Redis download] page. Here we'll use the RPM packages. 

We need to add a Fedora YUM repo for Redis and then install it:

[source]
----
# wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
# rpm -Uvh epel-release-6*.rpm
# yum -y install redis
# chkconfig redis on
----

Modify `/etc/redis.conf`, comment out the `bind` setting to have the server listen on all interfaces:

[source]
----
# If you want you can bind a single interface, if the bind option is not
# specified all the interfaces will listen for incoming connections.
#
#bind 127.0.0.1
----

After this we can start Redis:

[source]
----
# service redis start
----

We can now test Redis by using:

[source]
----
# redis-cli -h `hostname` ping
PONG
----

=== Optionally Install a different Transport

We need to have a transport installed and we can use the Redis instance that we have installed in the previous step. If you prefer to use a different transport then you can use either RabbitMQ or Kafka. The Redis instance will in that case only be used for the Analytics Repository.

==== Using Kafka as Transport

Hortonworks HDP supports Kafka installs using Ambari while Pivotal PHD does not. If you use Hortonworks HDP then you should create a Kafka service using Ambari. If you use Pivotal PHD then you need to install Kafka manually first and provide the connection parameters when you create the Spring XD service. Kafka can be downloaded from the link:http://kafka.apache.org/downloads.html[Kafka download] page.

==== Using RabbitMQ as Transport

You need to install RabbitMQ manually. You can get more complete instructions from the link:https://www.rabbitmq.com/download.html[Downloading and Installing RabbitMQ] page. Here are some commands that we have used for this:

[source]
----
# rpm -Uvh http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm
# yum install erlang
# rpm --import https://www.rabbitmq.com/rabbitmq-signing-key-public.asc
# wget https://www.rabbitmq.com/releases/rabbitmq-server/v3.5.3/rabbitmq-server-3.5.3-1.noarch.rpm
# yum install rabbitmq-server-3.5.3-1.noarch.rpm
----

To allow the `guest` user to connect we need to change the Rabbit config. Create a `/etc/rabbitmq/rabbitmq.config` file and add the following line:

[source]
----
[{rabbit, [{loopback_users, []}]}].
----

Then configure the RabbitMQ server to start on boot and start the service:

[source]
----
# chkconfig rabbitmq-server on
# service rabbitmq-server start
----

=== Verify Repository Setting for Spring XD using Ambari UI

Open the Ambari UI and log in as `admin`. Select `Admin` -> `Repositories` from the menu. Scroll down until you see the repository settings for Spring XD. They should read:

[width="80%",cols="1m,2m,6m",frame="topbot"]
|=====================================
|redhat6 |SPRINGXD-1.3        |http://repo.spring.io/yum-release/spring-xd/1.3/
|=====================================

=== Install Spring XD and create Spring XD service using Ambari UI

Open the Ambari UI and log in as `admin`. From the Dashboard click on "Actions + Add Service" on the left hand side under the list of services. Check "Spring XD" and click `Next ->`. Choose your hosts to run Spring XD master, slave and client. We recommend to install the master (xd-admin) and client (xd-shell) on the same host. Then, just click `Next ->` a couple of times.

==== Customize XD configuration

Under "Customize Services" we will need to make a few changes in the "Advanced springxd-site" section depending on which transport and distribution we are using.

.When using Kafka as transport:
************************************************
[width="95%",cols="1m,3m",frame="topbot"]
|=====================================
|hsql.server.port            | 9101
|server.port                 | 9393
|spring.rabbitmq.addresses   |
|spring.redis.host           | <hostname where redis is running>
|spring.redis.port           | 6379
|xd.messagebus.kafka.brokers | for PHD: <hostname where kafka is running>:<port for kafka:9092>
|                            | for HDP: leave blank since Ambari manages Kafka
|xd.transport                | kafka
|=====================================
************************************************

.When using RabbitMQ as transport:
************************************************
[width="95%",cols="1m,3m",frame="topbot"]
|=====================================
|hsql.server.port            | 9101
|server.port                 | 9393
|spring.rabbitmq.addresses   | <hostname where rabbitmq is running>:<port for rabbitmq:5672>
|spring.redis.host           | <hostname where redis is running>
|spring.redis.port           | 6379
|xd.messagebus.kafka.brokers | 
|xd.transport                | rabbit
|=====================================
************************************************

.When using Redis as transport:
************************************************
[width="95%",cols="1m,3m",frame="topbot"]
|=====================================
|hsql.server.port            | 9101
|server.port                 | 9393
|spring.rabbitmq.addresses   |
|spring.redis.host           | <hostname where redis is running>
|spring.redis.port           | 6379
|xd.messagebus.kafka.brokers | 
|xd.transport                | redis
|=====================================
************************************************

We should also add an entry for the custom module location in the "Custom springxd-site" section. The custom module location defaults to a local file location that won't work well for a distributed installation. We recommend setting the following property:

.Custom module location:
************************************************
[width="95%",cols="1m,3m",frame="topbot"]
|=====================================
|xd.customModule.home        | ${spring.hadoop.fsUri}/xd/custom-modules
|=====================================
************************************************

Then click `Next ->`.

Review the configuration and then click `Deploy ->`.

==== Test the Spring XD installation

To start the XD Shell, enter the following command on the host where the Spring XD client was installed:

[source]
----
# export JAVA_HOME=/usr/jdk64/jdk1.7.0_67
# xd-shell
----

Now, from the XD Shell run the following commands:

[source]
----
xd:>script --file /etc/springxd/conf/xd-shell.init
xd:>stream create ticktock --definition "time | hdfs" --deploy
----

To check that the stream works run the following commands:

[source]
----
xd:>hadoop fs ls /xd
Found 1 items
drwxrwxrwx   - spring-xd hdfs          0 2015-05-28 16:03 /xd/ticktock
----

Now, destroy the stream and display the output:

[source]
----
xd:>stream destroy ticktock
xd:>hadoop fs cat /xd/ticktock/*
2015-12-01 16:28:30
2015-12-01 16:28:31
2015-12-01 16:28:32
2015-12-01 16:28:33
2015-12-01 16:28:34
2015-12-01 16:28:35
2015-12-01 16:28:36
2015-12-01 16:28:37
2015-12-01 16:28:38
2015-12-01 16:28:39
2015-12-01 16:28:40
2015-12-01 16:28:41
2015-12-01 16:28:42
2015-12-01 16:28:43
2015-12-01 16:28:44
----

NOTE: [green yellow-background big]*That's it -- have fun!*

TIP: Just in case, Spring XD logs are in `var/log/springxd` on each host.
